# Lecture 12: Self-Supervised Learning

## What is Self-Supervised Learning?

```
    SUPERVISED vs SELF-SUPERVISED:

    SUPERVISED LEARNING:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Image + Human Label  â†’  Model  â†’  Prediction                 â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
    â”‚   â”‚   ğŸ±    â”‚  +  "cat"  â†’  CNN  â†’  "cat"                      â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
    â”‚                                                                 â”‚
    â”‚   âœ— Requires expensive human annotations                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    SELF-SUPERVISED LEARNING:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Create labels automatically from data itself                  â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚   â”‚  Image  â”‚  transform  â”‚ Modifiedâ”‚                          â”‚
    â”‚   â”‚         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  Image  â”‚  â† "pseudo-label"        â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
    â”‚                                                                 â”‚
    â”‚   Model learns to predict transformation / reconstruct / match â”‚
    â”‚                                                                 â”‚
    â”‚   âœ“ Unlimited training data (no human labels needed)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pretext Tasks

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    PRETEXT TASK                                 â”‚
    â”‚                                                                 â”‚
    â”‚   An auxiliary task designed to learn useful representations    â”‚
    â”‚                                                                 â”‚
    â”‚   Requirements:                                                 â”‚
    â”‚   1. Labels generated automatically                             â”‚
    â”‚   2. Solving task requires understanding image structure        â”‚
    â”‚   3. Learned features transfer to downstream tasks              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    SSL TRAINING PIPELINE:

    Stage 1: Pretraining (Self-Supervised)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Unlabeled Images â†’ Pretext Task â†’ Feature Extractor        â”‚
    â”‚   (millions)                        (learned backbone)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Stage 2: Fine-tuning (Supervised)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Pretrained Backbone â†’ Small Labeled Data â†’ Downstream Task â”‚
    â”‚   (frozen or fine-tuned)   (thousands)      (classification) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pretext Task: Rotation Prediction

```
    PREDICT IMAGE ROTATION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    ğŸ±   â”‚     â”‚   ğŸ±    â”‚     â”‚    ğŸ±   â”‚     â”‚   ğŸ±    â”‚
    â”‚         â”‚     â”‚    â†»    â”‚     â”‚   â†»â†»    â”‚     â”‚  â†»â†»â†»    â”‚
    â”‚   0Â°    â”‚     â”‚   90Â°   â”‚     â”‚  180Â°   â”‚     â”‚  270Â°   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   CNN    â”‚
                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    4-way classification
                    [0Â°, 90Â°, 180Â°, 270Â°]

    Intuition: To predict rotation, model must understand:
    - Object shape and structure
    - "Up" vs "down" (gravity, natural poses)
    - Scene context
```

## Pretext Task: Jigsaw Puzzles

```
    PREDICT PATCH ARRANGEMENT:

    Original Image           Shuffled Patches
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”           â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚ 1 â”‚ 2 â”‚ 3 â”‚   shuffle â”‚ 5 â”‚ 1 â”‚ 8 â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”€â”€â”€â”€â”€â”€â”€â–º â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
    â”‚ 4 â”‚ 5 â”‚ 6 â”‚           â”‚ 3 â”‚ 9 â”‚ 2 â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤           â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
    â”‚ 7 â”‚ 8 â”‚ 9 â”‚           â”‚ 6 â”‚ 4 â”‚ 7 â”‚
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜           â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
                                â”‚
                                â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   CNN    â”‚
                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
              Predict permutation (from fixed set)
              e.g., 1000 predefined permutations

    Intuition: Model must understand:
    - Spatial relationships
    - Object parts and their arrangement
    - Continuity of edges and textures
```

## Pretext Task: Masked Autoencoder (MAE)

```
    RECONSTRUCT MASKED PATCHES:

    Input Image              Masked (75%)           Reconstructed
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”       â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”     â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚       â”‚ â–‘ â”‚ â–‘ â”‚ â–  â”‚ â–‘ â”‚     â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
    â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚  â”€â”€â”€â–º â”‚ â–  â”‚ â–‘ â”‚ â–‘ â”‚ â–‘ â”‚ â”€â”€â–º â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
    â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚       â”‚ â–‘ â”‚ â–‘ â”‚ â–‘ â”‚ â–  â”‚     â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
    â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚       â”‚ â–‘ â”‚ â–  â”‚ â–‘ â”‚ â–‘ â”‚     â”‚ â–  â”‚ â–  â”‚ â–  â”‚ â–  â”‚
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜       â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜     â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

    â–  = visible     â–‘ = masked

    MAE ARCHITECTURE:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚   Visible    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Reconstructed â”‚
    â”‚   Patches    â”‚  Encoder   â”‚    â”‚  Decoder   â”‚    All Patches   â”‚
    â”‚   (25%)  â”€â”€â–º â”‚ (ViT-Base) â”‚ â”€â”€â–ºâ”‚ (Shallow)  â”‚ â”€â”€â–º  (100%)      â”‚
    â”‚              â”‚            â”‚    â”‚  + Mask    â”‚                   â”‚
    â”‚              â”‚            â”‚    â”‚  tokens    â”‚                   â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚                                                                 â”‚
    â”‚   Encoder only processes visible patches (efficient!)          â”‚
    â”‚   Decoder reconstructs in pixel space                          â”‚
    â”‚   Loss: MSE on masked patches only                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Contrastive Learning

```
    CORE IDEA: Pull similar things together, push different apart

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   CONTRASTIVE LEARNING                                          â”‚
    â”‚                                                                 â”‚
    â”‚              Feature Space                                      â”‚
    â”‚                                                                 â”‚
    â”‚        â— anchor (image A)                                       â”‚
    â”‚       â•±â”‚                                                        â”‚
    â”‚      â•± â”‚ pull                                                   â”‚
    â”‚     â•±  â”‚ closer                                                 â”‚
    â”‚    â•±   â”‚                                                        â”‚
    â”‚   â—â”€â”€â”€â”€â”¼â”€â”€â”€â— positive (aug of A)                               â”‚
    â”‚        â”‚                                                        â”‚
    â”‚   push â”‚ away                                                   â”‚
    â”‚        â”‚                                                        â”‚
    â”‚        â—‹ â—‹ â—‹ negatives (other images)                          â”‚
    â”‚                                                                 â”‚
    â”‚   Loss: -log( exp(sim(anchor, pos)) / Î£exp(sim(anchor, neg)) ) â”‚
    â”‚         = InfoNCE loss                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## SimCLR: Simple Contrastive Learning

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        SimCLR                                   â”‚
    â”‚                                                                 â”‚
    â”‚   Input Image x                                                 â”‚
    â”‚        â”‚                                                        â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                                   â”‚
    â”‚   â”‚ Random  â”‚  (crop, flip, color jitter, blur)                â”‚
    â”‚   â”‚ Aug t   â”‚                                                   â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                   â”‚
    â”‚        â”‚                                                        â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
    â”‚   â”‚   Aug   â”‚           â”‚   Aug   â”‚                             â”‚
    â”‚   â”‚   xÌƒáµ¢   â”‚           â”‚   xÌƒâ±¼   â”‚  â† positive pair            â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                             â”‚
    â”‚        â”‚                     â”‚                                  â”‚
    â”‚        â–¼                     â–¼                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
    â”‚   â”‚Encoder fâ”‚           â”‚Encoder fâ”‚  (shared weights)          â”‚
    â”‚   â”‚ (ResNet)â”‚           â”‚ (ResNet)â”‚                             â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                             â”‚
    â”‚        â”‚                     â”‚                                  â”‚
    â”‚        â–¼                     â–¼                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
    â”‚   â”‚ Proj g  â”‚           â”‚ Proj g  â”‚  (MLP projector)           â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                             â”‚
    â”‚        â”‚                     â”‚                                  â”‚
    â”‚        â–¼                     â–¼                                  â”‚
    â”‚       záµ¢                    zâ±¼                                  â”‚
    â”‚        â”‚                     â”‚                                  â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€ NT-Xent â”€â”€â”€â”€â”˜  (contrastive loss)             â”‚
    â”‚                   Loss                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Key ingredients:
    - Strong data augmentation
    - Large batch size (4096)
    - MLP projection head (discarded after pretraining)
```

## MoCo: Momentum Contrast

```
    PROBLEM: SimCLR needs huge batch for many negatives

    MOCO SOLUTION: Maintain queue of negatives

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         MoCo                                    â”‚
    â”‚                                                                 â”‚
    â”‚                    Query                    Key                 â”‚
    â”‚                                                                 â”‚
    â”‚                   Aug(x)                  Aug(x)                â”‚
    â”‚                     â”‚                       â”‚                   â”‚
    â”‚                     â–¼                       â–¼                   â”‚
    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚               â”‚ Encoder  â”‚            â”‚ Momentum â”‚              â”‚
    â”‚               â”‚   f_q    â”‚            â”‚ Encoder  â”‚              â”‚
    â”‚               â”‚          â”‚            â”‚   f_k    â”‚              â”‚
    â”‚               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
    â”‚                    â”‚                       â”‚                    â”‚
    â”‚                    â–¼                       â–¼                    â”‚
    â”‚                   q                       kâº                    â”‚
    â”‚                    â”‚                       â”‚                    â”‚
    â”‚                    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚                    â”‚      â”‚                                     â”‚
    â”‚                    â–¼      â–¼                                     â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
    â”‚              â”‚  Contrastive   â”‚ â—„â”€â”€ Queue: [kâ‚, kâ‚‚, ..., kâ‚™]   â”‚
    â”‚              â”‚     Loss       â”‚     (negatives from past)      â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
    â”‚                                                                 â”‚
    â”‚   Momentum update: f_k â† m Ã— f_k + (1-m) Ã— f_q  (m = 0.999)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Advantage: Can use 65K negatives with small batch size
```

## DINO: Self-Distillation Without Labels

```
    STUDENT-TEACHER WITH CENTERING:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         DINO                                    â”‚
    â”‚                                                                 â”‚
    â”‚         Global Crops              Local Crops                   â”‚
    â”‚         (large views)             (small views)                 â”‚
    â”‚              â”‚                         â”‚                        â”‚
    â”‚              â–¼                         â–¼                        â”‚
    â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
    â”‚        â”‚ Teacher  â”‚              â”‚ Student  â”‚                   â”‚
    â”‚        â”‚ Network  â”‚              â”‚ Network  â”‚                   â”‚
    â”‚        â”‚(momentum)â”‚              â”‚          â”‚                   â”‚
    â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚             â”‚                         â”‚                        â”‚
    â”‚             â–¼                         â–¼                        â”‚
    â”‚        Softmax(p_t/Ï„_t)          Softmax(p_s/Ï„_s)             â”‚
    â”‚             â”‚                         â”‚                        â”‚
    â”‚             â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                        â”‚
    â”‚             â””â”€â”€â”€â–ºâ”‚  CE Loss    â”‚â—„â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚                  â”‚ (p_t, p_s)  â”‚                               â”‚
    â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
    â”‚                                                                 â”‚
    â”‚   Teacher: momentum update (like MoCo)                         â”‚
    â”‚   Centering: subtract mean of teacher outputs (prevents collapse)â”‚
    â”‚                                                                 â”‚
    â”‚   Key finding: ViT + DINO learns semantic segmentation!        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## CLIP: Contrastive Language-Image Pretraining

```
    LEARN VISUAL CONCEPTS FROM TEXT:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         CLIP                                    â”‚
    â”‚                                                                 â”‚
    â”‚   Training Data: 400M (image, text) pairs from internet        â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚   â”‚  Image  â”‚                     â”‚     Text        â”‚           â”‚
    â”‚   â”‚   Iâ‚    â”‚                     â”‚ "a dog playing" â”‚           â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚        â”‚                                   â”‚                    â”‚
    â”‚        â–¼                                   â–¼                    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚   â”‚  Image  â”‚                     â”‚      Text       â”‚           â”‚
    â”‚   â”‚ Encoder â”‚                     â”‚    Encoder      â”‚           â”‚
    â”‚   â”‚ (ViT)   â”‚                     â”‚ (Transformer)   â”‚           â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚        â”‚                                   â”‚                    â”‚
    â”‚        â–¼                                   â–¼                    â”‚
    â”‚       I_e                                 T_e                   â”‚
    â”‚        â”‚                                   â”‚                    â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚                       â”‚                                         â”‚
    â”‚                 Cosine Similarity                               â”‚
    â”‚                                                                 â”‚
    â”‚   Contrastive Loss: Match I_i with T_i (diagonal)              â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
    â”‚   â”‚         Tâ‚    Tâ‚‚    Tâ‚ƒ   ...   T_N              â”‚          â”‚
    â”‚   â”‚   Iâ‚   [âœ“]   [âœ—]   [âœ—]  ...   [âœ—]              â”‚          â”‚
    â”‚   â”‚   Iâ‚‚   [âœ—]   [âœ“]   [âœ—]  ...   [âœ—]              â”‚          â”‚
    â”‚   â”‚   Iâ‚ƒ   [âœ—]   [âœ—]   [âœ“]  ...   [âœ—]              â”‚          â”‚
    â”‚   â”‚   ...                                           â”‚          â”‚
    â”‚   â”‚   I_N  [âœ—]   [âœ—]   [âœ—]  ...   [âœ“]              â”‚          â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ZERO-SHOT CLASSIFICATION:

    Image â†’ Encoder â†’ Compare with text embeddings of class names
                      "a photo of a dog"
                      "a photo of a cat"
                      "a photo of a bird"
                            â”‚
                            â–¼
                      Highest similarity = prediction
```

## SSL Methods Comparison

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              SELF-SUPERVISED LEARNING METHODS                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   Method     â”‚   Key Idea                                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Rotation    â”‚  Predict rotation angle (4-way)                 â”‚
    â”‚  Jigsaw      â”‚  Predict patch permutation                      â”‚
    â”‚  Colorizationâ”‚  Predict colors from grayscale                  â”‚
    â”‚  Inpainting  â”‚  Predict masked region                          â”‚
    â”‚  MAE         â”‚  Reconstruct 75% masked patches                 â”‚
    â”‚  SimCLR      â”‚  Contrastive with augmentations                 â”‚
    â”‚  MoCo        â”‚  Contrastive with momentum encoder              â”‚
    â”‚  DINO        â”‚  Self-distillation without labels               â”‚
    â”‚  CLIP        â”‚  Image-text contrastive                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    EVOLUTION:

    Pretext Tasks â†’ Contrastive Learning â†’ Masked Modeling
    (2014-2018)       (2019-2020)          (2021+)

    Key insight: Self-supervised can match or exceed supervised!
```

## Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Self-supervised learning uses data itself to create labels      â”‚
â”‚    - No human annotation needed                                    â”‚
â”‚    - Can leverage massive unlabeled datasets                       â”‚
â”‚                                                                    â”‚
â”‚ 2. Pretext tasks: predict transformations applied to image        â”‚
â”‚    - Rotation, jigsaw, colorization, inpainting                   â”‚
â”‚    - Simple but effective for learning structure                   â”‚
â”‚                                                                    â”‚
â”‚ 3. Contrastive learning: pull positives together, push negatives  â”‚
â”‚    - SimCLR: simple, needs large batch                            â”‚
â”‚    - MoCo: momentum encoder + queue for efficiency                â”‚
â”‚                                                                    â”‚
â”‚ 4. Masked modeling (MAE): reconstruct missing patches             â”‚
â”‚    - High masking ratio (75%)                                     â”‚
â”‚    - Efficient: encoder only sees visible patches                 â”‚
â”‚                                                                    â”‚
â”‚ 5. CLIP: connect vision and language                              â”‚
â”‚    - Enables zero-shot classification                              â”‚
â”‚    - Foundation for multimodal AI                                  â”‚
â”‚                                                                    â”‚
â”‚ 6. Self-supervised pretraining then supervised fine-tuning        â”‚
â”‚    is now standard practice                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
