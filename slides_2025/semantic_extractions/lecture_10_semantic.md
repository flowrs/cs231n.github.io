# Lecture 10: Video Understanding

## Video as 4D Tensor

```
    IMAGE vs VIDEO:

    2D Image                        Video (3D in space-time)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚                 â”‚   Frame T   â”‚
    â”‚   H Ã— W     â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   Ã— 3       â”‚                 â”‚  Frame T-1  â”‚
    â”‚             â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  Frame T-2  â”‚
                                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    3D Tensor: 3Ã—HÃ—W                â”‚     ...     â”‚
                                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                    â”‚   Frame 1   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                    4D Tensor: TÃ—3Ã—HÃ—W
                                    (or 3Ã—TÃ—HÃ—W)

    Video = Sequence of Images over Time
```

## Training on Video Clips

```
    RAW VIDEO â†’ TRAINING CLIPS

    Raw Video (long, high FPS):
    â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”
    â”‚1â”‚2â”‚3â”‚4â”‚5â”‚6â”‚7â”‚8â”‚9â”‚...                                       â”‚
    â””â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”˜
                            â†“ Sample short clips

    Training Clips (short, low FPS):
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚ 1 â”‚ 5 â”‚ 9 â”‚13 â”‚17 â”‚21 â”‚25 â”‚29 â”‚  = 8 frames
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
        stride = 4

    Clip Parameters:
    - T = number of frames (e.g., 8, 16, 32)
    - Ï„ = temporal stride (e.g., 4, 8)
    - Effective temporal coverage = T Ã— Ï„ frames
```

## Early Fusion vs Late Fusion vs 3D CNN

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    TEMPORAL FUSION STRATEGIES                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚    EARLY FUSION    â”‚    LATE FUSION     â”‚       3D CNN             â”‚
    â”‚                    â”‚                    â”‚                          â”‚
    â”‚    t1 t2 t3 t4     â”‚   t1  t2  t3  t4   â”‚    t1  t2  t3  t4        â”‚
    â”‚    â”‚  â”‚  â”‚  â”‚      â”‚    â”‚   â”‚   â”‚   â”‚   â”‚     â”‚   â”‚   â”‚   â”‚        â”‚
    â”‚    â””â”€â”€â”´â”€â”€â”´â”€â”€â”˜      â”‚    â–¼   â–¼   â–¼   â–¼   â”‚     â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜        â”‚
    â”‚        â”‚           â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â” â”‚         â”‚                â”‚
    â”‚  First conv        â”‚  â”‚2D â”‚2D â”‚2D â”‚2D â”‚ â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”‚
    â”‚  collapses time    â”‚  â”‚CNNâ”‚CNNâ”‚CNNâ”‚CNNâ”‚ â”‚    â”‚ 3D Conv â”‚           â”‚
    â”‚        â”‚           â”‚  â””â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”˜ â”‚    â”‚ 3D Pool â”‚           â”‚
    â”‚        â–¼           â”‚    â”‚   â”‚   â”‚   â”‚   â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”        â”‚    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜   â”‚         â”‚                â”‚
    â”‚    â”‚ 2D   â”‚        â”‚        â”‚           â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”‚
    â”‚    â”‚ CNN  â”‚        â”‚        â–¼           â”‚    â”‚ 3D Conv â”‚           â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”˜        â”‚    Fuse at end     â”‚    â”‚ 3D Pool â”‚           â”‚
    â”‚                    â”‚                    â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚
    â”‚ âœ— Loses temporal   â”‚ âœ— No temporal      â”‚         â”‚                â”‚
    â”‚   info early       â”‚   interaction      â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”‚
    â”‚                    â”‚                    â”‚    â”‚   FC    â”‚           â”‚
    â”‚                    â”‚                    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚                    â”‚                    â”‚                          â”‚
    â”‚                    â”‚                    â”‚ âœ“ Gradual temporal       â”‚
    â”‚                    â”‚                    â”‚   fusion                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 3D Convolution

```
    2D CONVOLUTION vs 3D CONVOLUTION:

    2D Conv (spatial only):           3D Conv (spatial + temporal):

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â”Œâ”€â”€â”€â”€â”€â”     â”‚                   â”‚ â”Œâ”€â”€â”€â”€â”€â”     â”‚  t1
    â”‚ â”‚kernelâ”‚    â”‚  HÃ—W              â”‚ â”‚     â”‚     â”‚
    â”‚ â”‚ 3Ã—3 â”‚    â”‚                   â”‚ â””â”€â”€â”€â”€â”€â”˜     â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”˜     â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ â”Œâ”€â”€â”€â”€â”€â”     â”‚  t2
                                      â”‚ â”‚kernelâ”‚    â”‚
    Slides over: H, W                 â”‚ â”‚3Ã—3Ã—3â”‚    â”‚
                                      â”‚ â””â”€â”€â”€â”€â”€â”˜     â”‚
                                      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                      â”‚ â”Œâ”€â”€â”€â”€â”€â”     â”‚  t3
                                      â”‚ â”‚     â”‚     â”‚
                                      â”‚ â””â”€â”€â”€â”€â”€â”˜     â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                      Slides over: T, H, W


    3D CNN ARCHITECTURE:

    Input: 3 Ã— 20 Ã— 64 Ã— 64  (CÃ—TÃ—HÃ—W)
           â”‚
           â–¼
    Conv3D(3Ã—3Ã—3, 3â†’12)  â†’  12 Ã— 20 Ã— 64 Ã— 64
           â”‚
           â–¼
    Pool3D(4Ã—4Ã—4)        â†’  12 Ã— 5 Ã— 16 Ã— 16
           â”‚
           â–¼
    Conv3D(3Ã—3Ã—3, 12â†’24) â†’  24 Ã— 5 Ã— 16 Ã— 16
           â”‚
           â–¼
    Pool3D(2Ã—4Ã—4)        â†’  24 Ã— 2 Ã— 4 Ã— 4
           â”‚
           â–¼
    Flatten + FC         â†’  Class scores
```

## Optical Flow

```
    MEASURING MOTION BETWEEN FRAMES:

    Frame t                 Frame t+1              Optical Flow
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚         â”‚             â”‚        â”‚   â†’  â†’  â†’   â”‚
    â”‚    â—        â”‚   â†’     â”‚       â—     â”‚   =    â”‚   â†’  â†’  â†’   â”‚
    â”‚             â”‚         â”‚             â”‚        â”‚   â†’  â†’  â†’   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Object at (x,y)         Object at (x+dx,y+dy)  Motion vectors
                                                   (dx, dy) per pixel

    Optical Flow encodes:
    - Direction of motion (angle)
    - Speed of motion (magnitude)

    Stack of flow frames as input:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  flow_x(t1), flow_y(t1)               â”‚
    â”‚  flow_x(t2), flow_y(t2)               â”‚
    â”‚  ...                                  â”‚  â†’ 2T channels
    â”‚  flow_x(tT), flow_y(tT)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Two-Stream Networks

```
    SEPARATING APPEARANCE AND MOTION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    TWO-STREAM NETWORK                           â”‚
    â”‚                                                                 â”‚
    â”‚   RGB Frames                      Optical Flow Stack            â”‚
    â”‚   (Appearance)                    (Motion)                      â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
    â”‚   â”‚ Frame t     â”‚                 â”‚ flow x,y    â”‚               â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚ stack       â”‚               â”‚
    â”‚          â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
    â”‚          â–¼                               â–¼                      â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
    â”‚   â”‚  Spatial    â”‚                 â”‚  Temporal   â”‚               â”‚
    â”‚   â”‚  Stream     â”‚                 â”‚  Stream     â”‚               â”‚
    â”‚   â”‚  (2D CNN)   â”‚                 â”‚  (2D CNN)   â”‚               â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
    â”‚          â”‚                               â”‚                      â”‚
    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
    â”‚                      â”‚                                          â”‚
    â”‚                      â–¼                                          â”‚
    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
    â”‚               â”‚   Fusion    â”‚                                   â”‚
    â”‚               â”‚  (Average)  â”‚                                   â”‚
    â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
    â”‚                      â”‚                                          â”‚
    â”‚                      â–¼                                          â”‚
    â”‚               Action Label                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Simonyan & Zisserman, NeurIPS 2014
```

## I3D: Inflated 3D ConvNet

```
    INFLATING 2D PRETRAINED WEIGHTS TO 3D:

    ImageNet pretrained 2D CNN â†’ Inflate to 3D for video

    2D Conv Filter:             3D Inflated Filter:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”‚             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚ â”‚ w w w â”‚   â”‚             â”‚ â”‚w/3 w/3â”‚   â”‚  t1
    â”‚ â”‚ w w w â”‚   â”‚   inflate   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚ â”‚ w w w â”‚   â”‚   â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚             â”‚ â”‚w/3 w/3â”‚   â”‚  t2
    â”‚   3Ã—3       â”‚             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”‚
                                â”‚ â”‚w/3 w/3â”‚   â”‚  t3
                                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                â”‚   3Ã—3Ã—3     â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Divide weights by temporal size to preserve output magnitude

    Two-Stream I3D:
    - RGB I3D stream (inflated from ImageNet weights)
    - Flow I3D stream (inflated from ImageNet weights)
    - Fuse predictions
```

## SlowFast Networks

```
    TWO PATHWAYS AT DIFFERENT FRAME RATES:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     SLOWFAST NETWORK                            â”‚
    â”‚                                                                 â”‚
    â”‚   Video Input                                                   â”‚
    â”‚       â”‚                                                         â”‚
    â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚       â”‚                      â”‚                              â”‚   â”‚
    â”‚       â–¼                      â–¼                              â”‚   â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚
    â”‚   â”‚  SLOW   â”‚           â”‚  FAST   â”‚                         â”‚   â”‚
    â”‚   â”‚ Pathway â”‚           â”‚ Pathway â”‚                         â”‚   â”‚
    â”‚   â”‚         â”‚           â”‚         â”‚                         â”‚   â”‚
    â”‚   â”‚ T/Î±     â”‚â—„â”€lateralâ”€â”€â”‚    T    â”‚                         â”‚   â”‚
    â”‚   â”‚ frames  â”‚ connectionâ”‚ frames  â”‚                         â”‚   â”‚
    â”‚   â”‚         â”‚           â”‚         â”‚                         â”‚   â”‚
    â”‚   â”‚ High    â”‚           â”‚ Low     â”‚                         â”‚   â”‚
    â”‚   â”‚ channelsâ”‚           â”‚ channelsâ”‚                         â”‚   â”‚
    â”‚   â”‚ (C)     â”‚           â”‚ (Î²C)    â”‚                         â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                         â”‚   â”‚
    â”‚        â”‚                     â”‚                              â”‚   â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚   â”‚
    â”‚                  â”‚                                          â”‚   â”‚
    â”‚                  â–¼                                          â”‚   â”‚
    â”‚           Classification                                    â”‚   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    SLOW pathway: Low frame rate (T/Î±), high capacity
                  Captures spatial semantics

    FAST pathway: High frame rate (T), low capacity (Î² â‰ˆ 1/8)
                  Captures fast motion

    Lateral connections: Fast â†’ Slow (motion informs appearance)
```

## Vision Transformers for Video

```
    ViViT: VIDEO VISION TRANSFORMER

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         ViViT                                   â”‚
    â”‚                                                                 â”‚
    â”‚   Video: T Ã— H Ã— W                                              â”‚
    â”‚       â”‚                                                         â”‚
    â”‚       â–¼ Divide into tubes (space-time patches)                  â”‚
    â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                            â”‚
    â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚  = n_t Ã— n_h Ã— n_w patches  â”‚
    â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                            â”‚
    â”‚       â”‚                                                         â”‚
    â”‚       â–¼ Linear projection + Position embedding                  â”‚
    â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                            â”‚
    â”‚   â”‚zâ‚ â”‚zâ‚‚ â”‚zâ‚ƒ â”‚zâ‚„ â”‚zâ‚… â”‚zâ‚† â”‚zâ‚‡ â”‚zâ‚ˆ â”‚  + [CLS] token            â”‚
    â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                            â”‚
    â”‚       â”‚                                                         â”‚
    â”‚       â–¼ Transformer Encoder                                     â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
    â”‚   â”‚  Multi-Head Self-Attention                     â”‚            â”‚
    â”‚   â”‚  (attends across space AND time)               â”‚            â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
    â”‚                         â”‚                                       â”‚
    â”‚                         â–¼                                       â”‚
    â”‚                    [CLS] â†’ FC â†’ Class                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    FACTORIZED ATTENTION (more efficient):

    Model 1: Spatial, then temporal
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Spatial attention within each frame â†’ Temporal across frames   â”‚
    â”‚                                                                 â”‚
    â”‚  t1: [â–  â–  â–  â– ] â”€â”€â–º spatial â”€â”€â”                                  â”‚
    â”‚  t2: [â–  â–  â–  â– ] â”€â”€â–º spatial â”€â”€â”¼â”€â”€â–º temporal â”€â”€â–º output          â”‚
    â”‚  t3: [â–  â–  â–  â– ] â”€â”€â–º spatial â”€â”€â”˜                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Video Action Recognition Tasks

```
    ACTION CLASSIFICATION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                               â”‚
    â”‚   Input Video                          Output                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
    â”‚   â”‚  ğŸƒ running â”‚                                             â”‚
    â”‚   â”‚   person    â”‚  â”€â”€â–º Model â”€â”€â–º "Running"                    â”‚
    â”‚   â”‚             â”‚                                             â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
    â”‚                                                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


    TEMPORAL ACTION LOCALIZATION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Video Timeline                                              â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚   â”‚  idle â”‚ jumping â”‚ idle â”‚ running â”‚ walking â”‚ idle   â”‚    â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚           â”‚         â”‚      â”‚         â”‚         â”‚              â”‚
    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
    â”‚           Action 1         Action 2   Action 3               â”‚
    â”‚           + timestamps     + timestamps                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


    VIDEO CAPTIONING:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Video â”€â”€â–º Encoder â”€â”€â–º Decoder â”€â”€â–º "A dog playing with      â”‚
    â”‚                                      a baby in the living     â”‚
    â”‚                                      room"                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Video Datasets and Benchmarks

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               VIDEO UNDERSTANDING DATASETS                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚    Dataset     â”‚    Task           â”‚    Scale                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ UCF-101        â”‚ Action classif.   â”‚ 101 classes, 13K clips    â”‚
    â”‚ Kinetics-400/600/700 â”‚ Action     â”‚ 400-700 classes, 500K+    â”‚
    â”‚ Something-V2   â”‚ Temporal reason.  â”‚ 174 classes, 220K         â”‚
    â”‚ AVA            â”‚ Spatial-temporal  â”‚ Person-centric actions    â”‚
    â”‚ Charades       â”‚ Multi-action      â”‚ 157 classes, daily acts   â”‚
    â”‚ ActivityNet    â”‚ Localization      â”‚ 200 classes, untrimmed    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    METRICS:
    - Top-1 / Top-5 Accuracy (classification)
    - mAP (mean Average Precision) for localization
```

## Model Comparison

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           VIDEO MODEL EVOLUTION                                â”‚
    â”‚                                                                â”‚
    â”‚   Method              â”‚ Top-1 (Kinetics-400)                  â”‚
    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
    â”‚   2D CNN per frame    â”‚     ~60%                              â”‚
    â”‚   Late Fusion         â”‚     ~65%                              â”‚
    â”‚   3D CNN (C3D)        â”‚     ~70%                              â”‚
    â”‚   Two-Stream          â”‚     ~75%                              â”‚
    â”‚   I3D                 â”‚     ~78%                              â”‚
    â”‚   SlowFast            â”‚     ~80%                              â”‚
    â”‚   Video Transformers  â”‚     ~85%+                             â”‚
    â”‚   (MViT, VideoMAE)                                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Video = 4D tensor (TÃ—HÃ—WÃ—C), requires temporal modeling         â”‚
â”‚                                                                    â”‚
â”‚ 2. Temporal fusion strategies:                                     â”‚
â”‚    - Early fusion: collapse time in first layer (loses info)      â”‚
â”‚    - Late fusion: independent frame processing (no interaction)   â”‚
â”‚    - 3D CNN: gradual fusion across space and time                 â”‚
â”‚                                                                    â”‚
â”‚ 3. Two-stream approach separates appearance (RGB) and motion      â”‚
â”‚    (optical flow) for complementary information                   â”‚
â”‚                                                                    â”‚
â”‚ 4. I3D inflates 2D pretrained weights to 3D, enabling transfer   â”‚
â”‚    from ImageNet to video                                         â”‚
â”‚                                                                    â”‚
â”‚ 5. SlowFast uses two pathways:                                    â”‚
â”‚    - Slow: high capacity, low frame rate (semantics)              â”‚
â”‚    - Fast: low capacity, high frame rate (motion)                 â”‚
â”‚                                                                    â”‚
â”‚ 6. Video Transformers (ViViT, MViT) achieve SOTA by attending    â”‚
â”‚    across space-time; factorized attention for efficiency         â”‚
â”‚                                                                    â”‚
â”‚ 7. Key insight: motion and appearance often need different        â”‚
â”‚    processing - temporal structure matters!                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
