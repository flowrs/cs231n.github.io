# Lecture 9: Object Detection and Segmentation

## Computer Vision Task Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPUTER VISION TASKS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Classification â”‚   Detection     â”‚   Segmentation  â”‚  Instance Seg         â”‚
â”‚                 â”‚                 â”‚                 â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚           â”‚  â”‚  â”‚  â”Œâ”€â”€â”     â”‚  â”‚  â”‚â–“â–“â–“â–“â–“      â”‚  â”‚  â”‚â–“â–“â–“â–“â–“      â”‚        â”‚
â”‚  â”‚   ğŸ•      â”‚  â”‚  â”‚  â”‚ğŸ•â”‚     â”‚  â”‚  â”‚â–“â–“â–“â–“â–“      â”‚  â”‚  â”‚â–“â–“â–“â–“â–“      â”‚        â”‚
â”‚  â”‚           â”‚  â”‚  â”‚  â””â”€â”€â”˜     â”‚  â”‚  â”‚â–“â–“â–“â–“â–“â–“â–“    â”‚  â”‚  â”‚â–’â–’â–’â–’â–’â–’â–’    â”‚        â”‚
â”‚  â”‚           â”‚  â”‚  â”‚           â”‚  â”‚  â”‚â–“â–“â–“â–“â–“â–“â–“â–“   â”‚  â”‚  â”‚â–’â–’â–’â–’â–’â–’â–’â–’   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                 â”‚                 â”‚                 â”‚                       â”‚
â”‚  "dog"          â”‚  "dog" + bbox   â”‚  Pixel labels   â”‚  Separate instances   â”‚
â”‚  Single label   â”‚  Where is it?   â”‚  What class?    â”‚  Which object?        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Vision Transformer (ViT) Encoder

```
    INPUT IMAGE â†’ PATCH EMBEDDINGS â†’ TRANSFORMER

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    ViT ENCODER                                  â”‚
    â”‚                                                                 â”‚
    â”‚   Image (224Ã—224)         Patches (16Ã—16 each = 14Ã—14 patches)  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”               â”‚
    â”‚   â”‚             â”‚         â”‚zâ‚€â‚€â”‚zâ‚€â‚â”‚zâ‚€â‚‚â”‚...â”‚zâ‚€,â‚â‚ƒâ”‚               â”‚
    â”‚   â”‚             â”‚    â†’    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤               â”‚
    â”‚   â”‚   IMAGE     â”‚         â”‚zâ‚â‚€â”‚zâ‚â‚â”‚zâ‚â‚‚â”‚...â”‚     â”‚  = 196 tokens â”‚
    â”‚   â”‚             â”‚         â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤               â”‚
    â”‚   â”‚             â”‚         â”‚...â”‚...â”‚...â”‚...â”‚zâ‚â‚ƒ,â‚â‚ƒ               â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜               â”‚
    â”‚                                    â”‚                            â”‚
    â”‚                                    â–¼                            â”‚
    â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
    â”‚                         â”‚ Linear Projection â”‚                    â”‚
    â”‚                         â”‚  + Position Enc   â”‚                    â”‚
    â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚                                  â–¼                              â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚   â”‚              TRANSFORMER ENCODER Ã— N                    â”‚    â”‚
    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚   â”‚  â”‚         Multi-Head Self-Attention              â”‚    â”‚    â”‚
    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚   â”‚                       â–¼                                â”‚    â”‚
    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[+]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
    â”‚   â”‚  â”‚              Layer Norm                       â”‚     â”‚    â”‚
    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
    â”‚   â”‚                       â–¼                                â”‚    â”‚
    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚   â”‚  â”‚                    MLP                          â”‚    â”‚    â”‚
    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚   â”‚                       â–¼                                â”‚    â”‚
    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[+]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
    â”‚   â”‚  â”‚              Layer Norm                       â”‚     â”‚    â”‚
    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                                  â”‚                              â”‚
    â”‚                                  â–¼                              â”‚
    â”‚                         â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                   â”‚
    â”‚                         â”‚câ‚€â‚€â”‚câ‚€â‚â”‚câ‚€â‚‚â”‚...â”‚câ‚‚â‚‚â”‚ Context vectors   â”‚
    â”‚                         â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Vision Transformer Decoder (Image Captioning)

```
    ENCODER OUTPUT + DECODER â†’ CAPTION

    Image Context         Decoder (Autoregressive)
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚câ‚€â‚€â”‚câ‚€â‚â”‚...â”‚         [START] â†’ "person" â†’ "wearing" â†’ "hat" â†’ [END]
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤              â”‚          â”‚           â”‚        â”‚
    â”‚câ‚â‚€â”‚câ‚â‚â”‚...â”‚              â–¼          â–¼           â–¼        â–¼
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚...â”‚...â”‚câ‚‚â‚‚â”‚ â”€â”€â”€K,Vâ”€â”€â–ºâ”‚      TRANSFORMER DECODER Ã— N          â”‚
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜         â”‚                                        â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚  Masked Multi-Head Self-Attentionâ”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚                â–¼                       â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚  Multi-Head Cross-Attention      â”‚  â”‚
                          â”‚  â”‚  Q = decoder, K,V = encoder      â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚                â–¼                       â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚           MLP + LayerNorm        â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â–¼
                          â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
                          â”‚yâ‚€ â”‚yâ‚ â”‚yâ‚‚ â”‚yâ‚ƒ â”‚yâ‚„ â”‚ = "person wearing hat [END]"
                          â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
```

## R-CNN Family Evolution

```
    R-CNN (2014)                    Fast R-CNN (2015)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. Region proposals â”‚         â”‚ 1. Region proposals â”‚
    â”‚    (Selective Search)â”‚         â”‚    (Selective Search)â”‚
    â”‚         â”‚           â”‚         â”‚         â”‚           â”‚
    â”‚         â–¼ (~2000)   â”‚         â”‚         â–¼           â”‚
    â”‚ 2. Warp each region â”‚         â”‚ 2. CNN on FULL imageâ”‚
    â”‚    to fixed size    â”‚         â”‚    (shared features)â”‚
    â”‚         â”‚           â”‚         â”‚         â”‚           â”‚
    â”‚         â–¼           â”‚         â”‚         â–¼           â”‚
    â”‚ 3. CNN for EACH     â”‚         â”‚ 3. RoI Pooling      â”‚
    â”‚    region (slow!)   â”‚         â”‚    (crop + resize)  â”‚
    â”‚         â”‚           â”‚         â”‚         â”‚           â”‚
    â”‚         â–¼           â”‚         â”‚         â–¼           â”‚
    â”‚ 4. SVM + bbox reg   â”‚         â”‚ 4. FC layers        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ~47s per image                  ~2s per image


    Faster R-CNN (2015)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                          â”‚
    â”‚   Image â”€â”€â–º CNN Backbone â”€â”€â–º Feature Map                 â”‚
    â”‚                                   â”‚                      â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚                    â”‚              â”‚              â”‚       â”‚
    â”‚                    â–¼              â–¼              â–¼       â”‚
    â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚             â”‚  Region  â”‚   â”‚   RoI    â”‚   â”‚  Class   â”‚   â”‚
    â”‚             â”‚ Proposal â”‚â”€â”€â–ºâ”‚ Pooling  â”‚â”€â”€â–ºâ”‚  + BBox  â”‚   â”‚
    â”‚             â”‚ Network  â”‚   â”‚          â”‚   â”‚   Head   â”‚   â”‚
    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                 RPN                                      â”‚
    â”‚             (learned!)                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ~0.2s per image (real-time possible!)
```

## Region Proposal Network (RPN)

```
    ANCHOR BOXES AT EACH LOCATION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                Feature Map Location                      â”‚
    â”‚                        â—                                 â”‚
    â”‚                                                          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚    â”‚         â”‚  â”‚               â”‚  â”‚                 â”‚   â”‚
    â”‚    â”‚  1:1    â”‚  â”‚     1:2       â”‚  â”‚       2:1       â”‚   â”‚
    â”‚    â”‚         â”‚  â”‚               â”‚  â”‚                 â”‚   â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                          â”‚
    â”‚    3 aspect ratios Ã— 3 scales = 9 anchors per location  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    RPN OUTPUTS (per anchor):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â€¢ Objectness score (object vs background) â”‚
    â”‚  â€¢ Bounding box refinement (dx, dy, dw, dh)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    RPN LOSS:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ L = L_cls(objectness) + Î» Ã— L_reg(bbox refinement)      â”‚
    â”‚                                                         â”‚
    â”‚ Positive anchor: IoU > 0.7 with any GT box             â”‚
    â”‚ Negative anchor: IoU < 0.3 with all GT boxes           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Faster R-CNN: Four Losses

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    FASTER R-CNN TRAINING                        â”‚
    â”‚                                                                 â”‚
    â”‚   Image â”€â”€â–º CNN â”€â”€â–º Feature Map                                 â”‚
    â”‚                         â”‚                                       â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
    â”‚              â”‚                     â”‚                            â”‚
    â”‚              â–¼                     â–¼                            â”‚
    â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚        â”‚   RPN    â”‚          â”‚    RoI   â”‚                       â”‚
    â”‚        â”‚          â”‚ proposalsâ”‚  Pooling â”‚                       â”‚
    â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚          â”‚                       â”‚
    â”‚        â”‚ â”‚L1:clsâ”‚ â”‚          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
    â”‚        â”‚ â”‚L2:regâ”‚ â”‚          â”‚ â”‚L3:clsâ”‚ â”‚                       â”‚
    â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚          â”‚ â”‚L4:regâ”‚ â”‚                       â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
    â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
    â”‚                                                                 â”‚
    â”‚   FOUR LOSSES:                                                  â”‚
    â”‚   L1: RPN classification (object vs background)                â”‚
    â”‚   L2: RPN bounding box regression                              â”‚
    â”‚   L3: Detection classification (which class?)                  â”‚
    â”‚   L4: Detection bounding box regression                        â”‚
    â”‚                                                                 â”‚
    â”‚   Total Loss = L1 + L2 + L3 + L4                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## YOLO (You Only Look Once)

```
    SINGLE-SHOT DETECTION:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Input Image          Grid (SÃ—S)         Predictions          â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚   ğŸ•  ğŸš²   â”‚      â”‚   â”‚   â”‚   â”‚     â”‚ Each cell predicts:â”‚ â”‚
    â”‚  â”‚             â”‚ â”€â”€â–º  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤ â”€â”€â–º â”‚ â€¢ B bounding boxes â”‚ â”‚
    â”‚  â”‚             â”‚      â”‚   â”‚   â”‚   â”‚     â”‚ â€¢ C class probs    â”‚ â”‚
    â”‚  â”‚             â”‚      â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”‚                    â”‚ â”‚
    â”‚  â”‚             â”‚      â”‚   â”‚   â”‚   â”‚     â”‚ Output: SÃ—SÃ—(BÃ—5+C)â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                                                               â”‚
    â”‚  Per bounding box: (x, y, w, h, confidence)                   â”‚
    â”‚  Per cell: class probabilities P(class | object)              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    YOLO PREDICTION PIPELINE:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  SÃ—S     â”‚      â”‚  Bounding    â”‚      â”‚    Final      â”‚
    â”‚  Grid    â”‚  +   â”‚  Boxes +     â”‚  â†’   â”‚  Detections   â”‚
    â”‚  Input   â”‚      â”‚  Confidence  â”‚      â”‚  (NMS)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Class Prob    â”‚
                      â”‚ Map (colors   â”‚
                      â”‚ = classes)    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Advantages:
    âœ“ Very fast (real-time: 45 FPS)
    âœ“ Global context (sees full image)
    âœ“ End-to-end trainable

    Disadvantages:
    âœ— Struggles with small objects
    âœ— Fixed grid limits detections
```

## DETR (Detection Transformer)

```
    END-TO-END OBJECT DETECTION WITH TRANSFORMERS:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         DETR                                    â”‚
    â”‚                                                                 â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚   â”‚  Image  â”‚     â”‚              BACKBONE                     â”‚  â”‚
    â”‚   â”‚         â”‚ â”€â”€â–º â”‚   CNN â”€â”€â–º Feature Map + Pos Encoding     â”‚  â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                        â”‚                        â”‚
    â”‚                                        â–¼                        â”‚
    â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚                   â”‚         TRANSFORMER ENCODER            â”‚    â”‚
    â”‚                   â”‚  Self-attention over spatial features  â”‚    â”‚
    â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                                        â”‚                        â”‚
    â”‚                                        â–¼                        â”‚
    â”‚   Object Queries  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚   (N learnable)   â”‚         TRANSFORMER DECODER            â”‚    â”‚
    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Cross-attention: queries attend to    â”‚    â”‚
    â”‚                   â”‚  encoder features                      â”‚    â”‚
    â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                                        â”‚                        â”‚
    â”‚                                        â–¼                        â”‚
    â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚                   â”‚     N PARALLEL PREDICTIONS               â”‚   â”‚
    â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
    â”‚                   â”‚  â”‚Class  â”‚ â”‚Class  â”‚ ...  â”‚Class  â”‚     â”‚   â”‚
    â”‚                   â”‚  â”‚+ BBox â”‚ â”‚+ BBox â”‚      â”‚+ BBox â”‚     â”‚   â”‚
    â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
    â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    KEY INNOVATION: Bipartite Matching Loss
    - Hungarian algorithm matches predictions to GT
    - No need for NMS (non-maximum suppression)
    - Set-based loss for permutation invariance
```

## Semantic Segmentation

```
    GOAL: Classify EVERY PIXEL

    Input Image              Output Segmentation
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚      â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
    â”‚   ğŸ•     ğŸŒ³    â”‚  â”€â”€â–º â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–’â–’â–’â–’â–’â–’â–’â–’â”‚
    â”‚                 â”‚      â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–’â–’â–’â–’â–’â–’â–’â–’â”‚
    â”‚   grass         â”‚      â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â–“ = dog    â–’ = tree    â–‘ = grass


    FULLY CONVOLUTIONAL NETWORK (FCN):

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                             â”‚
    â”‚  Input    â”€â”€â–º ENCODER (downsampling) â”€â”€â–º DECODER (upsampling)â”‚
    â”‚  HÃ—WÃ—3         â†“ conv + pool                â†‘ upconv        â”‚
    â”‚                â†“ conv + pool                â†‘ upconv        â”‚
    â”‚                â†“ conv + pool                â†‘ upconv        â”‚
    â”‚                â””â”€â”€â–º bottleneck â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
    â”‚                                                             â”‚
    â”‚  Output: HÃ—WÃ—C (C = number of classes)                      â”‚
    â”‚  Each pixel gets class probabilities                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## U-Net Architecture

```
    ENCODER-DECODER WITH SKIP CONNECTIONS:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         U-NET                                  â”‚
    â”‚                                                                â”‚
    â”‚   Input                                              Output    â”‚
    â”‚   â”Œâ”€â”€â”€â”                                              â”Œâ”€â”€â”€â”     â”‚
    â”‚   â”‚   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚     â”‚
    â”‚   â”‚64 â”‚â”€â”€â”                                      â”Œâ”€â”€â”€â–ºâ”‚64 â”‚     â”‚
    â”‚   â””â”€â”¬â”€â”˜  â”‚ skip connection                      â”‚    â””â”€â”€â”€â”˜     â”‚
    â”‚     â”‚    â”‚                                      â”‚              â”‚
    â”‚     â–¼    â”‚                                      â–²              â”‚
    â”‚   â”Œâ”€â”€â”€â”  â”‚                                    â”Œâ”€â”´â”€â”            â”‚
    â”‚   â”‚128â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚128â”‚            â”‚
    â”‚   â””â”€â”¬â”€â”˜  â”‚                                    â””â”€â–²â”€â”˜            â”‚
    â”‚     â”‚    â”‚                                      â”‚              â”‚
    â”‚     â–¼    â”‚                                      â”‚              â”‚
    â”‚   â”Œâ”€â”€â”€â”  â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”´â”€â”            â”‚
    â”‚   â”‚256â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Bottleneckâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚256â”‚            â”‚
    â”‚   â””â”€â”€â”€â”˜  â”‚          â”‚   (512)   â”‚             â””â”€â”€â”€â”˜            â”‚
    â”‚          â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
    â”‚          â”‚                                                     â”‚
    â”‚   ENCODER              LOW RES               DECODER           â”‚
    â”‚   (contract)           FEATURES              (expand)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Skip connections:
    - Concatenate encoder features with decoder features
    - Preserves fine-grained spatial information
    - Critical for precise boundaries
```

## Instance Segmentation

```
    MASK R-CNN = Faster R-CNN + Mask Branch

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       MASK R-CNN                                â”‚
    â”‚                                                                 â”‚
    â”‚   Image â”€â”€â–º CNN Backbone â”€â”€â–º Feature Map                        â”‚
    â”‚                                  â”‚                              â”‚
    â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚                           â”‚             â”‚                       â”‚
    â”‚                           â–¼             â–¼                       â”‚
    â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚                      â”‚   RPN   â”‚   â”‚   RoI   â”‚                  â”‚
    â”‚                      â”‚         â”‚â”€â”€â–ºâ”‚ Align   â”‚ (not pool!)      â”‚
    â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚
    â”‚                                         â”‚                       â”‚
    â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚                           â”‚             â”‚             â”‚         â”‚
    â”‚                           â–¼             â–¼             â–¼         â”‚
    â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚                      â”‚  Class  â”‚   â”‚  BBox   â”‚   â”‚  Mask   â”‚    â”‚
    â”‚                      â”‚  Head   â”‚   â”‚  Head   â”‚   â”‚  Head   â”‚    â”‚
    â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                           â”‚             â”‚             â”‚         â”‚
    â”‚                           â–¼             â–¼             â–¼         â”‚
    â”‚                        "dog"      (x,y,w,h)      â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚                                                 â”‚â–“â–“â–“â–“â–“â–“â–“â”‚      â”‚
    â”‚                                                 â”‚â–“â–“â–“â–“â–“â–“â–“â”‚      â”‚
    â”‚                                                 â””â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    RoI Align vs RoI Pool:
    - RoI Pool: quantizes to grid â†’ misalignment
    - RoI Align: bilinear interpolation â†’ precise alignment
```

## Multi-Scale Feature Pyramids (FPN)

```
    FEATURE PYRAMID NETWORK:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                              â”‚
    â”‚   Bottom-Up           Top-Down + Lateral Connections         â”‚
    â”‚   (ResNet)                                                   â”‚
    â”‚                                                              â”‚
    â”‚   â”Œâ”€â”€â”€â”              â”Œâ”€â”€â”€â”                                   â”‚
    â”‚   â”‚C5 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚P5 â”‚ small objects (high res)         â”‚
    â”‚   â””â”€â”¬â”€â”˜    1Ã—1 conv  â””â”€â”¬â”€â”˜                                   â”‚
    â”‚     â”‚                  â”‚ upsample                            â”‚
    â”‚   â”Œâ”€â–¼â”€â”              â”Œâ”€â–¼â”€â”                                   â”‚
    â”‚   â”‚C4 â”‚ â”€â”€â–º + â”€â”€â”€â”€â”€â”€â–ºâ”‚P4 â”‚                                   â”‚
    â”‚   â””â”€â”¬â”€â”˜              â””â”€â”¬â”€â”˜                                   â”‚
    â”‚     â”‚                  â”‚ upsample                            â”‚
    â”‚   â”Œâ”€â–¼â”€â”              â”Œâ”€â–¼â”€â”                                   â”‚
    â”‚   â”‚C3 â”‚ â”€â”€â–º + â”€â”€â”€â”€â”€â”€â–ºâ”‚P3 â”‚                                   â”‚
    â”‚   â””â”€â”¬â”€â”˜              â””â”€â”¬â”€â”˜                                   â”‚
    â”‚     â”‚                  â”‚ upsample                            â”‚
    â”‚   â”Œâ”€â–¼â”€â”              â”Œâ”€â–¼â”€â”                                   â”‚
    â”‚   â”‚C2 â”‚ â”€â”€â–º + â”€â”€â”€â”€â”€â”€â–ºâ”‚P2 â”‚ large objects (low res)          â”‚
    â”‚   â””â”€â”€â”€â”˜              â””â”€â”€â”€â”˜                                   â”‚
    â”‚                                                              â”‚
    â”‚   Each Pn used for detecting objects at different scales     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detection Metrics

```
    INTERSECTION OVER UNION (IoU):

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”
    â”‚   â”‚  Predicted  â”‚   â”‚
    â”‚   â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¤ Ground
    â”‚   â”‚      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â”‚   â”‚ Truth
    â”‚   â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    IoU = Area of Intersection / Area of Union
        = â–ˆâ–ˆâ–ˆâ–ˆ / (Pred + GT - â–ˆâ–ˆâ–ˆâ–ˆ)

    IoU thresholds:
    - IoU > 0.5 â†’ "correct" detection (PASCAL VOC)
    - IoU > 0.5:0.95 â†’ average across thresholds (COCO)


    PRECISION-RECALL:

    Precision = TP / (TP + FP)     "Of detections, how many correct?"
    Recall    = TP / (TP + FN)     "Of GT objects, how many found?"

    Average Precision (AP) = Area under PR curve
    mAP = mean AP across all classes
```

## Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Vision Transformers treat images as sequences of patches        â”‚
â”‚    - Encoder: self-attention over patch embeddings                 â”‚
â”‚    - Decoder: cross-attention for captioning/detection             â”‚
â”‚                                                                    â”‚
â”‚ 2. R-CNN family evolution:                                         â”‚
â”‚    R-CNN â†’ Fast R-CNN â†’ Faster R-CNN (learned proposals)          â”‚
â”‚                                                                    â”‚
â”‚ 3. Two-stage vs One-stage detection:                              â”‚
â”‚    - Two-stage (R-CNN): propose then classify (accurate)          â”‚
â”‚    - One-stage (YOLO): direct prediction (fast)                   â”‚
â”‚                                                                    â”‚
â”‚ 4. DETR: end-to-end detection with transformers                   â”‚
â”‚    - Object queries attend to image features                       â”‚
â”‚    - Bipartite matching loss (no NMS needed)                      â”‚
â”‚                                                                    â”‚
â”‚ 5. Segmentation architectures:                                     â”‚
â”‚    - FCN: fully convolutional, encoder-decoder                    â”‚
â”‚    - U-Net: skip connections for fine details                     â”‚
â”‚    - Mask R-CNN: instance segmentation with RoI Align             â”‚
â”‚                                                                    â”‚
â”‚ 6. Multi-scale matters: FPN for detecting all object sizes        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
